{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31a1044f",
   "metadata": {},
   "source": [
    "## 오차행렬! 출력\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0345c263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello,world!\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello,world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "388085e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class MyFakeClassifier(BaseEstimator):\n",
    "    def fit(self,X,y):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.zeros( (len(X),1),dtype=bool)\n",
    "    \n",
    "digits = load_digits()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45e1da12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "[[ 0.  0.  3. ... 12. 14.  7.]\n",
      " [ 0.  1.  9. ... 10.  1.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 0.  0.  1. ... 16. 13.  1.]\n",
      " [ 0.  1. 11. ... 13. 16.  5.]\n",
      " [ 0.  0.  6. ...  6.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "y = (digits.target ==7).astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data,y,random_state=11)\n",
    "\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54c5ba8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "레이블 테스트 세트 크기 : (450,)\n",
      "테스트 세트 레이블 0 과 1의 분포도\n",
      "0    405\n",
      "1     45\n",
      "dtype: int64\n",
      "모든 예측을 0으로 하여도 정확도는:0.900\n"
     ]
    }
   ],
   "source": [
    "#불균형한 레이블 데이터 분포도 확인\n",
    "print('레이블 테스트 세트 크기 :', y_test.shape)\n",
    "print('테스트 세트 레이블 0 과 1의 분포도')\n",
    "print(pd.Series(y_test).value_counts())\n",
    "\n",
    "#Dummy Classifier 로 학습/예측/정확도 평가\n",
    "fakeclf = MyFakeClassifier()\n",
    "fakeclf.fit(X_train,y_train)\n",
    "fakepred = fakeclf.predict(X_test)\n",
    "print('모든 예측을 0으로 하여도 정확도는:{:.3f}'.format(accuracy_score(y_test,fakepred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5bef0c",
   "metadata": {},
   "source": [
    "# 오차행렬 시작\n",
    "\n",
    "### TN,FP,FN,TP\n",
    "\n",
    "**구분은 가능하고 API 사용하기**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb83f158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[405,   0],\n",
       "       [ 45,   0]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test,fakepred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5023f6a",
   "metadata": {},
   "source": [
    "# 정밀도와 재현율\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16a9be6",
   "metadata": {},
   "source": [
    "## 정밀도 {TP/(FP+TP)}\n",
    "\n",
    "정밀도 : Positive 로 예측한 값 중 예측과 실제값이 일치한 데이터의 비율\n",
    "\n",
    "ex : 실제 Positive 를 Negative 로 판단하면 큰 지장이 생김\n",
    "암 판단여부 , 보험사기 적중시\n",
    "\n",
    "대신에 Negative 를 Postivie 로 판단해도 그냥 재검사나 재확인 절차를 거치면 됌.\n",
    "\n",
    "## 재현율 {TP/(FN+TP)}\n",
    "\n",
    "재현율 : 실제 값이 Positive 인 대상 중 예측과 실제 값이 Positive 로 일치한 비율\n",
    "\n",
    "\n",
    "# 코드\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8fdb637e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score , recall_score, confusion_matrix\n",
    "\n",
    "def get_clf_eval(y_test,pred):\n",
    "    confusion = confusion_matrix(y_test,pred)\n",
    "    accuracy = accuracy_score(y_test,pred)\n",
    "    precision = precision_score(y_test,pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    print('오차행렬')\n",
    "    print(confusion)\n",
    "    print('정확도: {0:.4f}, 정밀도= {1:.4f}, 재현율: {2:.4f}'.format(accuracy,precision,recall))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd00534a",
   "metadata": {},
   "source": [
    "# 타이타닉 데이터셋\n",
    "\n",
    "캐글에 있습니다.\n",
    "https://www.kaggle.com/c/titanic/data?select=train.csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01ffcaf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived  Pclass  \\\n",
      "0              1         0       3   \n",
      "1              2         1       1   \n",
      "2              3         1       3   \n",
      "3              4         1       1   \n",
      "4              5         0       3   \n",
      "..           ...       ...     ...   \n",
      "886          887         0       2   \n",
      "887          888         1       1   \n",
      "888          889         0       3   \n",
      "889          890         1       1   \n",
      "890          891         0       3   \n",
      "\n",
      "                                                  Name     Sex   Age  SibSp  \\\n",
      "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                             Allen, Mr. William Henry    male  35.0      0   \n",
      "..                                                 ...     ...   ...    ...   \n",
      "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
      "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
      "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
      "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
      "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
      "\n",
      "     Parch            Ticket     Fare Cabin Embarked  \n",
      "0        0         A/5 21171   7.2500   NaN        S  \n",
      "1        0          PC 17599  71.2833   C85        C  \n",
      "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3        0            113803  53.1000  C123        S  \n",
      "4        0            373450   8.0500   NaN        S  \n",
      "..     ...               ...      ...   ...      ...  \n",
      "886      0            211536  13.0000   NaN        S  \n",
      "887      0            112053  30.0000   B42        S  \n",
      "888      2        W./C. 6607  23.4500   NaN        S  \n",
      "889      0            111369  30.0000  C148        C  \n",
      "890      0            370376   7.7500   NaN        Q  \n",
      "\n",
      "[891 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#원본 데이터를 재로딩, 데이터 가공, 학습 데이터/테스트 데이터 분할.\n",
    "\n",
    "titanic_df = pd.read_csv('C:/DB/titanic_train.csv')\n",
    "print(titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0f627aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 생성된 MyDummyClassifier를 이용해 타이타닉 생존자 예측 수행\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "## Null 처리 함수\n",
    "def fillna(df):\n",
    "    df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "    df['Cabin'].fillna('N', inplace=True)\n",
    "    df['Embarked'].fillna('N', inplace=True)\n",
    "    df['Fare'].fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "## 머신러닝에 불필요한 피처 제거\n",
    "def drop_features(df):\n",
    "    df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "## Label Encoding 수행\n",
    "def format_features(df):\n",
    "    df['Cabin'] = df['Cabin'].str[:1]\n",
    "    features = ['Cabin', 'Sex', 'Embarked']\n",
    "    for feature in features:\n",
    "        le = LabelEncoder()\n",
    "        le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "## 앞에서 실행한 Data Preprocessing 함수 호출\n",
    "def transform_features(df):\n",
    "    df = fillna(df)\n",
    "    df = drop_features(df)\n",
    "    df = format_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "065b8f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pclass  Sex        Age  SibSp  Parch     Fare  Cabin  Embarked\n",
      "0         3    1  22.000000      1      0   7.2500      7         3\n",
      "1         1    0  38.000000      1      0  71.2833      2         0\n",
      "2         3    0  26.000000      0      0   7.9250      7         3\n",
      "3         1    0  35.000000      1      0  53.1000      2         3\n",
      "4         3    1  35.000000      0      0   8.0500      7         3\n",
      "..      ...  ...        ...    ...    ...      ...    ...       ...\n",
      "886       2    1  27.000000      0      0  13.0000      7         3\n",
      "887       1    0  19.000000      0      0  30.0000      1         3\n",
      "888       3    0  29.699118      1      2  23.4500      7         3\n",
      "889       1    1  26.000000      0      0  30.0000      2         0\n",
      "890       3    1  32.000000      0      0   7.7500      7         2\n",
      "\n",
      "[891 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df = titanic_df.drop('Survived',axis=1) #axis 가 0 이면 행 방향 , axis 가 1 이면 열 방향\n",
    "X_titanic_df = transform_features(X_titanic_df)\n",
    "print(X_titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bb79f899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차행렬\n",
      "[[108  10]\n",
      " [ 14  47]]\n",
      "정확도: 0.8659, 정밀도= 0.8246, 재현율: 0.7705\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test , y_train , y_test = train_test_split(X_titanic_df, y_titanic_df, \n",
    "                                                     test_size=0.20, random_state=11)\n",
    "lr_clf=LogisticRegression(solver='liblinear') #로지스틱 회귀의 최적화 알고리즘 유형 지정\n",
    "#soliver 는 기본값이 lbfgs 이며 작은 데이터 세트의 경유는 liblinear 이 약간 성능이 좋은 경향이 있습니다. lbfgs 는 크고 다중 분류에 적합! \n",
    "lr_clf.fit(X_train,y_train)\n",
    "pred = lr_clf.predict(X_test)\n",
    "get_clf_eval(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "58434bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_proba()결과 Shape : (179, 2)\n",
      "pred_proba array에서 앞 3개만 샘플로 추출 \n",
      ": [[0.44935228 0.55064772]\n",
      " [0.86335513 0.13664487]\n",
      " [0.86429645 0.13570355]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred_proba = lr_clf.predict_proba(X_test)\n",
    "pred = lr_clf.predict(X_test)\n",
    "print('pred_proba()결과 Shape : {0}'.format(pred_proba.shape))\n",
    "print('pred_proba array에서 앞 3개만 샘플로 추출 \\n:', pred_proba[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e7a1ce",
   "metadata": {},
   "source": [
    "pred_proba 는 예측확률로 lr_clf 로 이전에 정의한 로지스틱 회귀의 liblinear 을 쓰겠다는 의미입니다.\n",
    "그래서 proba.shape 를 한 줄로 적겠따는 의미로 실패확률 44.9 , 성공확률 55.0 (이거맞나?확실히는 모르겠지만) 이런느낌인거 같습니다."
   ]
  },
  {
   "cell_type": "raw",
   "id": "071aeda6",
   "metadata": {},
   "source": [
    "    # 밑에는 예측확률 array 와 예측 결과값 array 를 병합해 예측 확률과 결과값을 보겠습니다.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "07781cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "두 개의 class 중에서 더 큰 확률을 클래스 값으로 예측 \n",
      " [[0.44935228 0.55064772 1.        ]\n",
      " [0.86335513 0.13664487 0.        ]\n",
      " [0.86429645 0.13570355 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "pred_proba_result = np.concatenate([pred_proba, pred.reshape(-1,1)], axis=1)\n",
    "print('두 개의 class 중에서 더 큰 확률을 클래스 값으로 예측 \\n',pred_proba_result[:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f147787",
   "metadata": {},
   "source": [
    "# 트레이드 오프 이해\n",
    "\n",
    "predict() 는 ndarray(n -dimesional 로 다차원을 의미합니다.) 가 정해진 임계값(0.5) 이용하여 최종 예측 정했습니다.\n",
    "\n",
    "__predict() 구현__\n",
    "\n",
    "Binarizer 클래스 : threshold 변수를 특정값설정과 객체 생성\n",
    "Binarizer 객체의 fit_transform() 으로 ndarray 의 값을 지정된 threshold 보다 같거나 작으면 0 , 크면 1로 변환\n",
    "\n",
    "한마디로 binarizer 로 임계값을 지정하여 2진수 즉, 둘 중 하나로 결정!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9f30784a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "X =[[1,-1,2],\n",
    "   [2,0,0],\n",
    "   [0, 1.1, 1.2]]\n",
    "\n",
    "#X 의 개별원소가 threshold 값보다 같거나 작은면 0을 , 크면 1로 반환\n",
    "binarizer = Binarizer(threshold=1.1)\n",
    "print(binarizer.fit_transform(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f0d2ff",
   "metadata": {},
   "source": [
    "## 최종 평가 예측값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "06ca61b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차행렬\n",
      "[[108  10]\n",
      " [ 14  47]]\n",
      "정확도: 0.8659, 정밀도= 0.8246, 재현율: 0.7705\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "#Binarizer 의 threshold 설정\n",
    "custom_threshold =0.5\n",
    "\n",
    "#predict_proba() 반환값의 2번째 칼럼, 즉 Positive 클래스 칼럼 하나만 추출해 Binarizer 적용\n",
    "# Positive 만 추출이란 의미\n",
    "pred_proba_1 = pred_proba[:,1].reshape(-1,1) #reshape 로 열을 하나만으로 진행\n",
    "binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_1)\n",
    "custom_predict = binarizer.transform(pred_proba_1)\n",
    "\n",
    "get_clf_eval(y_test,custom_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd4ce68",
   "metadata": {},
   "source": [
    "### 이제 임곗값 조정하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e67e0dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차행렬\n",
      "[[97 21]\n",
      " [11 50]]\n",
      "정확도: 0.8212, 정밀도= 0.7042, 재현율: 0.8197\n"
     ]
    }
   ],
   "source": [
    "custom_threshold =0.4\n",
    "\n",
    "pred_proba_1 = pred_proba[:,1].reshape(-1,1) \n",
    "binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_1)\n",
    "custom_predict = binarizer.transform(pred_proba_1)\n",
    "\n",
    "get_clf_eval(y_test,custom_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6428c16e",
   "metadata": {},
   "source": [
    "### 와우. 재현율 급상승 , 정밀도 급하락\n",
    "\n",
    "---\n",
    "= Positive 의 확률을 늘렸으니까 당연히 정밀도는 분모에 P가 많아서 하락 , 재현율은 TP(Positive 라 예측해서 맞춘 경우)가 올라서 상승\n",
    "이라 볼 수 있습니다.\n",
    "\n",
    "### 그런데 약간 문제인 것은 정확도가 줄었다는 점!\n",
    "FP (Positive 로 예측했는데 틀린 경우가 11개나 급상승)\n",
    "TP (Positive 로 예측했는데 맞은 경우는 겨우 3개 상승)\n",
    "따라서 더 안좋다고 예측할 수 있습니다.\n",
    "\n",
    "그러면 threshold 를 여러개 만들어서 한 번에 평가해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7b967525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ㅡㅡ임곗값: 0.4 ㅡㅡㅡ\n",
      "오차행렬\n",
      "[[97 21]\n",
      " [11 50]]\n",
      "정확도: 0.8212, 정밀도= 0.7042, 재현율: 0.8197\n",
      "ㅡㅡ임곗값: 0.45 ㅡㅡㅡ\n",
      "오차행렬\n",
      "[[105  13]\n",
      " [ 13  48]]\n",
      "정확도: 0.8547, 정밀도= 0.7869, 재현율: 0.7869\n",
      "ㅡㅡ임곗값: 0.5 ㅡㅡㅡ\n",
      "오차행렬\n",
      "[[108  10]\n",
      " [ 14  47]]\n",
      "정확도: 0.8659, 정밀도= 0.8246, 재현율: 0.7705\n",
      "ㅡㅡ임곗값: 0.55 ㅡㅡㅡ\n",
      "오차행렬\n",
      "[[111   7]\n",
      " [ 16  45]]\n",
      "정확도: 0.8715, 정밀도= 0.8654, 재현율: 0.7377\n",
      "ㅡㅡ임곗값: 0.6 ㅡㅡㅡ\n",
      "오차행렬\n",
      "[[113   5]\n",
      " [ 17  44]]\n",
      "정확도: 0.8771, 정밀도= 0.8980, 재현율: 0.7213\n"
     ]
    }
   ],
   "source": [
    "thresholds = [0.4,0.45,0.50,0.55,0.60] #threshold 는 한계점이다.\n",
    "def get_eval_by_threshold(y_test,pred_proba_c1,thresholds):\n",
    "    #thresholds list 를 차례대로 반복(iteration) 하며 평가(evaluation)\n",
    "    for custom_threshold in thresholds:\n",
    "        binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_c1) \n",
    "        #지금까지 pred_proba_1 썼는데 c1에 대해  정의안하고 바로 가능한가? (의문점)\n",
    "        custom_predict =binarizer.transform(pred_proba_c1)\n",
    "        print('ㅡㅡ임곗값:', custom_threshold, 'ㅡㅡㅡ')\n",
    "        get_clf_eval(y_test, custom_predict)\n",
    "        \n",
    "get_eval_by_threshold(y_test,pred_proba[:,1].reshape(-1,1), thresholds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ade6fe",
   "metadata": {},
   "source": [
    "## 정밀도와 재현율이 0.78 , 0.78 로 임곗값이 0.45 일 때 거의 똑같다!\n",
    "\n",
    "### ? 이런 평가지표 코드에 대해 precision_recall_curve() API 가 있다고 하네요.;;;;;; 하.. 왜 이제 알려줘..\n",
    "### 그래도 많이 배웠다.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a4b400",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "#레이블 값이 1일 때 예측확률\n",
    "pred_proba_class1 = lr_clf.predict_proba(X_test)[:,1]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
